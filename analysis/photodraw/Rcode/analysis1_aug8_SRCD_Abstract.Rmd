---
title: "PhotoDraw-Exp1-RecognitionAnalysis"
author: "Bria Long"
date: "8/6/2018"
output: html_document
---

```{r setup, echo = FALSE}
library(knitr)
opts_chunk$set(echo = TRUE)
library(tidyverse)
library(assertthat)
library(ggthemes)
library(lme4)
library(langcog)
library(lmerTest)
library(viridis)
theme_set(theme_few())
```

## Load data and do basic preprocessing.
```{r}
## Read in data outputs from turk data - true/false recognition 
r <- read.csv("preprocessed_data/photodraw_recognition_ratings.csv") %>%
  as.tibble() 

## redo age for subject who lied about his age -- at Bing so can't be a 6-year-old. Noted in run sheet.
r$age[r$sessionId=="e11533079944053"]=4

## refactor levels to that semantic condition is first, then working memory, then perception
r$condition <- factor(r$condition, levels = c("S", "W", "P"))

d <- read_csv("preprocessed_data/photodraw_data_Aug8.csv") %>%
  select(-X1) %>%
  filter(!is.na(age)) %>%
  mutate(imNameShort = paste0(category, '_sketch', '_', session_id,'_',condition, '_', age,'.png'))

```

#### Convert alphanumeric age to numeric age in python csv
```{r}
d <- d %>%
  group_by(session_id) %>%
  mutate(age_char = strsplit(age,"e")[[1]][2]) %>%
  mutate(age_num = as.numeric(age_char)) %>%
  select(-age) %>%
  rename(age = age_num)
```

#### Join ratings and python datasets
```{r}
joined <- left_join(r,d)
```

### Sanity check number of raters per image
```{r}
ratersPerImage <- r %>%
  distinct(imageName, workerid) %>%
  group_by(imageName) %>%
  summarize(count = n()) 

assert_that(sum(ratersPerImage$count==30)==(length(unique(r$imageName))))
```

#### Sanity check number of kids in each condition and age
```{r}
r %>%
  distinct(sessionId, condition, age) %>%
  group_by(condition) %>%
  summarize(count = n()) %>%
  kable()
```

#### And distribution across age groups and conditions
```{r}
r %>%
  distinct(sessionId, condition, age) %>%
  group_by(condition,age) %>%
  summarize(count = n()) 
```


# Part 2: Descriptive statistics 
### Take a look at the raw rating data 
Highest chosen category is correct one;  confusions look more or less reasonable.
```{r}
ratingConfusions <- r %>%
  group_by(category, rating)  %>%
  summarize(number = n()) %>%
  group_by(category) %>%
  mutate(prop = number / sum(number)) %>%
  complete(rating, fill = list(prop = 0))

## Reorder so that we have a meaningful confusion matrix
ratingConfusions$category <- factor(ratingConfusions$category, levels = c("rabbit","cat", "cup","shoe","train"))

ratingConfusions$rating <- factor(ratingConfusions$rating, levels = c( "rabbit","cat", "cup","shoe","train","bus","car","couch","bird","mouse","dog","horse","bear","lion","arm",
"hat","book","bottle","spoon","lamp","other","cannot tell at all"))

## Plot it
ggplot(ratingConfusions, 
       aes(x = rating, y = category, fill = prop)) + 
  geom_tile() + 
  ylab("True Category") + 
  xlab("Rated as") + 
  scale_fill_viridis(limits = c(0, .6),option="viridis") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5))
```


### Look at num strokes / duration per condition

```{r}
ggplot(d, aes(num_strokes)) +
  geom_histogram(binwidth=2) + 
  facet_grid(~condition)

ggplot(d, aes(draw_duration)) +
  geom_histogram(binwidth=2) + 
  facet_grid(~condition)

```



## How different are individual participants?
```{r}

## Get proportion recognized for each image
correctByImage <- r %>%
  group_by(imNameShort) %>% # group by subjects
  mutate(image_correct = mean(correct)) %>%
  distinct(sessionId, category, age, image_correct, condition)

## Get proportion recognized for each participant
indiv <- r %>%
  group_by(sessionId) %>%
  mutate(sub_correct = mean(correct)) %>%
  distinct(sessionId, sub_correct, age) %>% # get unique combos of sessionId and average 
  ungroup() %>%
  mutate(sessionId = fct_reorder(sessionId, sub_correct, .desc=TRUE))

## Plot individual children ordered from best to worst
# ggplot(indiv, aes(x = sessionId, y = sub_correct, col = age)) +
#   geom_point() + 
#   # theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
#   theme(axis.text.x = element_blank())+
#   xlab("Individual children") +
#   ylab("Proportion Recognized") +
#   scale_color_viridis() +
#   geom_hline(yintercept=1/22, col='grey') # plot chance line 

ggplot(indiv, aes(x = age, y = sub_correct, col = age)) +
  geom_point() + 
  # theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
  xlab("Age") +
  ylab("Proportion Recognized") +
  scale_color_viridis() +
  geom_hline(yintercept=1/22, col='grey') # plot chance line 
```


##  How does recognizability vary acrosscondition ?
```{r}
corbyConditionAndSubID <- r %>%
  group_by(sessionId) %>%
  mutate(meanCorrect = mean(correct)) %>%
  distinct(sessionId,meanCorrect,condition) %>% # get rid of duplicates
  group_by(condition) %>%
  multi_boot_standard(col = "meanCorrect")  

ggplot(corbyConditionAndSubID, aes(x = condition, y = mean, col=condition)) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper))  

```

### Look at individual children's performance in these conditions by their age
```{r}
corbyChild <- r %>%
  group_by(condition,sessionId, age) %>%
  mutate(avgCorrect = mean(correct)) 

ggplot(corbyChild, aes(x = age, y = avgCorrect, col=age)) + 
  geom_jitter(width = .01, alpha = .5)  +
  facet_grid(~condition) + 
  scale_color_viridis() +
  ylab("Proportion Recognized")
```

##  How does recognizability vary across age and condition, collapsing across items?
```{r}
## Get the percent recognized for each age group / condition
corbyCondition <- r %>%
  group_by(sessionId, age, condition) %>% # group by subjects
  summarise(meanCorrect=mean(correct)) %>% # calculate mean correct (subject-level average correct)
  group_by(condition,age) %>% ## critical step: group by BOTH condition and age to get CIs for each combination of age (4,5,6,7) and condition (S,W,P)
  multi_boot_standard(col = "meanCorrect")  

ggplot(corbyCondition, aes(x = age, y = mean, col=age)) + 
  scale_color_viridis()  +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
  facet_grid(~condition) 
```

## At the image level,how do num strokes / draw duration / avg_stroke_legth relate to recognizability?
```{r} 
corByItem <- joined %>%
  group_by(imNameShort) %>%
  mutate(avgCorrect = mean(correct)) %>% # IMAGE level correctness
  distinct(imNameShort, avgCorrect, draw_duration, num_strokes, avg_stroke_length,age, condition)
```

```{r}
ggplot(corByItem, aes(x = num_strokes, y = avgCorrect, col=condition)) +
    geom_jitter(width = .1, alpha = .5) +
    facet_grid(~age)

ggplot(corByItem, aes(x = draw_duration, y = avgCorrect, col=condition)) +
    geom_jitter(width = .1, alpha = .5) +
    facet_grid(~age)
```

## How does this trend break down by the catergory that children drew?
```{r}
ggplot(correctByImage, aes(x = condition, y = image_correct, col=age)) + 
  geom_point() +
  facet_wrap(~category) + 
  scale_color_viridis() 

ggplot(correctByImage, aes(x = condition, y = image_correct, col=age)) + 
  geom_jitter() +
  facet_wrap(~category) 
```

# Part 3: Inferential Statistics

## Inferential analyses: Non-linear mixed effect model with random slopes for items and random intercepts for participants. 
```{r}
corbySketch <- r %>%
  group_by(imNameShort) %>%
  mutate(propCorrect=mean(correct)) %>%
  distinct(imNameShort, condition, age, category, propCorrect, sessionId) 

# scale age
corbySketch$age_sc = scale(corbySketch$age, scale = FALSE) # center but don't scale age

## Adding random slopes on participants causes the model to fail to converge, only keeping random intercepts.
model_lmer <- lmer(propCorrect ~ age_sc*condition + (1 | sessionId) + (condition | category),  data = corbySketch)

model_summary = summary(model_lmer)$coef
```
### Check residuals of the model

Seem relatively evenly distributed around zero; suggests lmer isn't too bad of a fit.
```{r}
plot(corbySketch$age,resid(model_lmer))
plot(corbySketch$condition,resid(model_lmer))
```

### Get out some model predictions and plot them on top of both the raw data for each sketch and at the participant-averaged level

```{r}
predicted_df = data.frame(lmer_predictions = predict(model_lmer, corbySketch), age=corbySketch$age, condition=corbySketch$condition)

## Model prediction lines overlaid on raw data fed to the model
ggplot(data = predicted_df, aes(x=age, y=lmer_predictions)) +
  facet_grid(~condition) +
  scale_color_viridis()  +
  stat_smooth(method="lm", col='grey') + # plot smoothed line over predictions
  scale_x_discrete(limits=c(4,5,6,7),labels=c("4 yrs", "5 yrs", "6 yrs", "7 yrs")) +
  geom_jitter(data = corbySketch, aes(x=age, y=propCorrect, col=age)) # now plot raw corbysketch data
```

```{r}

## Model prediction lines overlaid on subject-level CI data
ggplot(data = predicted_df, aes(x=age, y=lmer_predictions)) +
  facet_grid(~condition) +
  stat_smooth(method="lm", col='grey') + # plot smoothed line
  geom_pointrange(data = corbyCondition,aes(x = age, y = mean, col=age, ymin = ci_lower, ymax = ci_upper)) + 
  xlab("Children's Age") +
  ylab("Proportion Recognized")

```

## Exploratory analysis: We have a somewhat uneven distribution of kids across ages (though even across condition). Do these results hold when we bin by "younger" and "older" kids to get a more even split?

### Plot how accuracy differs by these age group and condition
```{r}
r <- r %>%
  mutate(age_group = cut(age, c(3.9, 5, 8), labels = c("4-5","6-7"))) 

corbyAgeGroup <- r %>%
  group_by(sessionId)%>%
  mutate(meanCorrect = mean (correct)) %>%
  distinct(sessionId, age_group, condition, meanCorrect)%>%
  group_by(condition, age_group) %>%
  multi_boot_standard(col="meanCorrect")

ggplot(corbyAgeGroup, aes(x = condition, y = mean, col=age_group)) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper))
```

### Run inferential model statistics for age group
```{r}
corbySketch <- corbySketch %>%
  mutate(age_group = cut(age, c(3.9, 5, 8), labels = c("4-5","6-7"))) 

model_lmer <- lmer(propCorrect ~ age_group*condition + (1 | sessionId) + (condition | category),  data = corbySketch)
summary(model_lmer)
```

Looks like we still see an interaction between age_group and condition, though the main effect of 4-5 year-olds and 6-7 year-olds is no longer significant on it's own.


SRCD Abstract:

The role of memory in childrenâ€™s drawings of object categories
Bria Long, Judy Fan, Yi Feng, Renata Chai, & Michael C. Frank

Consistent with prior work (Long, Fan, & Frank, 2018), we found a strong effect of age; older children produced overall more recognizable drawings (b = `r round(model_summary[1,'Estimate'],3)`, SE =`r round(model_summary[1,'Std. Error'],3)`, z = `r round(model_summary[1,'t value'],3)`, p =`r round(model_summary[1,'Pr(>|t|)'],3)`). Contrary to our expectations, we found that overall children did not draw more recognizable drawings in the perception or working memory conditions than the semantic condition (perception condition M =`r round(corbyConditionAndSubID[3,'mean'],3)`% recognized, semantic condition, M=`r round(corbyConditionAndSubID[1,'mean'],3)`%, working memory condition, M=`r round(corbyConditionAndSubID[2,'mean'],3)`%). However, we  found an interaction between age and the perception condition (b=`r round(model_summary[6,'Estimate'],3)`, SE=`r round(model_summary[6,'Std. Error'],3)`, z= `r round(model_summary[6,'t value'],3)`, p=`r round(model_summary[6,'Pr(>|t|)'],3)`):  younger children drew less recognizable drawings in the perception condition, while the recognizability of older children's drawings slightly increased.



