---
title: "Drawing-Recognition-Analyses-Prereg"
author: "Bria Long"
date: "5/8/2019, updated 7/2019"
output: 
  html_document:
    toc: true
    theme: cerulean
---

# Preprocessing
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(ggplot2)
library(assertthat)
library(langcog)
library(viridis)
library(ggthemes)
library(lme4)
library(lmerTest)

```

## Load data
### Import recognition data from each run of recoggames: here, animalgame & vehiclegame
```{r}
#
animal_game <- read.csv("recognition_data/animalgame.csv") %>%
  as.tibble() %>%
  mutate(exp = 'animalgame') %>%
  select(-X)
#
vehicle_game <- read.csv("recognition_data/vehiclegame.csv") %>%
  as.tibble() %>%
  mutate(exp = 'vehiclegame') %>%
  select(-X)
#
biganimal_game <- read.csv("recognition_data/biganimalgame.csv") %>%
  as.tibble() %>%
  mutate(exp = 'biganimalgame') %>%
  select(-X)

object_game <- read.csv("recognition_data/objectgame.csv") %>%
  as.tibble() %>%
  mutate(exp = 'objectgame') %>%
  select(-X)

recog_data <- animal_game %>%
  full_join(vehicle_game)%>%
  full_join(biganimal_game) %>%
  full_join(object_game)

## make copy for editing
orig_d  <- recog_data
d <- recog_data
```

### Make variables correct types in dataset
```{r}
# make similar levels
d$clicked_category = as.factor(d$clicked_category)
d$intended_category = factor(d$intended_category, levels=levels(d$clicked_category))

# compute accurcy
d <- d %>%
  mutate(correct_or_not = (clicked_category == intended_category))  %>%
  mutate(recognizer_age_numeric = str_split_fixed(recognizer_age, 'age',2)[,2])

d$recognizer_age <- factor(d$recognizer_age, levels = c('age2','age3','age4','age5','age6','age7','age8','age9','age10','adult'))

```


## Data filtering
### Filter non-compliant subjects & trials: 
```{r}
##Filter out adults, those that didn't get past more than 1 real trial, and trials with RTs that are way too long or short

adults <- d %>%
  filter(recognizer_age == 'adult')

didnt_start <- d %>%
  group_by(sessionId) %>%
  mutate(count_trials = max(trial_num)) %>%
  filter(count_trials < 5)

# do actual filtering here
d <- d %>%
  filter(!sessionId %in% didnt_start$sessionId) %>%
  filter(!sessionId %in% adults$sessionId) %>%
  filter(RT>100 & RT<10000) # super long or super short trial

```

### Calculate performance on photo catch trials; visualize for each subject; compile list of off-task subjects
```{r}
# threshold : 75% correct
threshold=.9

# compute avg correct photo trials for each subject
photo_correct <- d %>%
  group_by(sessionId,recognizer_age) %>%
  filter(producer_age == "photo") %>%
  summarize(avg_photo_correct = mean(correct_or_not)) 

# visualize these data by each age group
ggplot(photo_correct, aes(x=recognizer_age, y=avg_photo_correct, col=recognizer_age)) +
  geom_jitter(alpha=.6) +
  scale_color_viridis(discrete=TRUE) +
  geom_hline(yintercept=threshold)

# make a list of the subjects who don't meet our threshold
bad_subs <- photo_correct %>%
  filter(avg_photo_correct < threshold) ## includes subjects who got 75% correct, excludes all those below
```

### Filter out subs who don't meet photo correct threshold
```{r}
# filter bad subs
d <- d %>%
  filter(!sessionId %in% bad_subs$sessionId)

# check that we did this right
photo_trials_by_sub <- d %>%
  filter(producer_age == 'photo') %>%
  group_by(sessionId) %>%
  summarize(avg_correct = mean(correct_or_not))

# make sure this is true.
assert_that(sum(photo_trials_by_sub$avg_correct<threshold)==0)

```

### Finally, filter kids that didn't have valid trials on both photo/sketch trials
```{r}
cor_by_trial_type <- d %>%
  mutate(photo_or_not = (producer_age == 'photo')) %>%
  group_by(photo_or_not,sessionId) %>%
  summarize(count_cor = sum(correct_or_not), count_items = n(), avg_correct = count_cor / count_items) 

only_one_type <- cor_by_trial_type %>%
  group_by(sessionId) %>%
  summarize(count_ids = n()) %>%
  filter(count_ids == 1)

# filter these subjects
d <- d %>%
  filter(!sessionId %in% only_one_type$sessionId)

```

### Exploratory: filter kids that had low accuracy
```{r}
low_accuracy <- cor_by_trial_type %>%
  filter(avg_correct<.5)

# filter low acc subjects (not in prereg but in attempt to equalize age groups even more)
d <- d %>%
  filter(!sessionId %in% low_accuracy$sessionId)

```

### Calculate number of trials per kid (not adult) after these exclusions and report exclusions
```{r}
num_trials_per_kid <- d %>%
  # filter(!sessionId %in% adults$sessionId) %>% # exclude adults (prereg code, error)
  filter(recognizer_age != "adult") %>% # exclude adults
  group_by(sessionId) %>%
  summarize(max_trials = max(trial_num)) %>%
  summarize(average_trials = mean(max_trials))

num_kids_per_exp <- d %>%
  filter(recognizer_age != "adult") %>% # exclude adults
  group_by(exp,recognizer_age) %>%
  summarize(num_subs = length(unique(sessionId)))

##
```

First, we excluded children who started the game but did not complete more than 1 trial after the practice trials (N = `r length(unique(didnt_start$sessionId))` participants) and the `r length(unique(adults$sessionId))` adults who participated. We also excluded all trials with RTs slower than 10s or faster than 100ms, judging these to be off-task responses. Next, we excluded participants on the basis of their performance on practice and catch trials; given that these catch trials presented a very easy recognition task, we excluded participants who did not acheive at least 75\% accuracy on these trials (N= `r length(bad_subs$sessionId)`). The remaining `r length(unique(d$sessionId))` who met this criterion completed an average of `r round(mean(num_trials_per_kid$average_trials),2)` trials. 
On total, we analyzed `r length(d$correct_or_not)` trials where children recognized each others drawings.

### Exclusion rates in each age bin; see that we are mostly filtering out young kids not on task.
```{r}
bad_subs_descriptives <- orig_d %>%
  filter(sessionId %in% bad_subs$sessionId) %>%
  group_by(sessionId) %>%
  summarize(count_trials = n(), recognizer_age = recognizer_age[1]) %>%
  group_by(recognizer_age) %>%
  summarize(count_subs = n(), avg_trials = mean(count_trials))

kable(bad_subs_descriptives)
```

### Calculate number of subs left in each age 
```{r}
d %>%
  group_by(recognizer_age) %>%
  summarize(num_subs = length(unique(sessionId))) %>%
  kable()
```

## First set of descriptives
### How are recognizers doing on photo trials aross age? Looks pretty flat.
```{r}
by_recognizer_photo <- d %>% 
  group_by(recognizer_age) %>%
  filter(producer_age == 'photo') %>%
  group_by(sessionId,recognizer_age) %>% 
  summarize(indiv_photo_correct = mean(correct_or_not)) %>% # average first over individual participants
  group_by(recognizer_age) %>%
  multi_boot_standard(col = 'indiv_photo_correct') 

by_recognizer_photo$recognizer_age <- factor(by_recognizer_photo$recognizer_age, levels = c('age2','age3','age4','age5','age6','age7','age8','age9','age10','adult'))

ggplot(by_recognizer_photo,aes(x=recognizer_age, y=mean, col = recognizer_age)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  scale_color_viridis(discrete = "TRUE") + 
  ylab('Proportion recognized - PHOTO') +
  ylim(.75,1) + # can't be lower than 75% correct or higher than 1
  theme_few()
```


### Look at overall recognition by recognizer age; looks like we should exclude 2 year-olds.
```{r}
by_recognizer <- d %>%
  group_by(recognizer_age) %>%
  filter(producer_age != 'photo') %>%
  multi_boot_standard(col = 'correct_or_not')

# make levels in reasonable order
by_recognizer$recognizer_age <- factor(by_recognizer$recognizer_age, levels = c('age2','age3','age4','age5','age6','age7','age8','age9','age10','adult'))

ggplot(by_recognizer,aes(x=recognizer_age, y=mean, col = recognizer_age)) +
  theme_few() +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  scale_color_viridis(discrete = "TRUE") + 
  ylab('Proportion drawings recognized') +
  ylim(.25,.8) +
  geom_smooth() 
```


### Look at use of "don't know" buton across age; roughly goes down with recognizer age.
```{r}
by_recognizer_dont_know <- d %>%
  mutate(dont_know = (clicked_category == 'dont_know')) %>%
  group_by(recognizer_age) %>%
  multi_boot_standard(col = 'dont_know') 

ggplot(by_recognizer_dont_know,aes(x=recognizer_age, y=mean, col = recognizer_age)) +
  theme_few() +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  scale_color_viridis(discrete = "TRUE") + 
  ylab('Proportion trials selected "dont know"') +
  geom_smooth() 
```

## Updated filtering 
For later, fine-grain analyses: given uneven distribution of subjects and performance from 2-year-olds, create new age bins that (1) exclude 2-year-olds and (2) group together older kids.  
```{r}
## filter recognition data to just kids and wrangle variables
kids_sketches_d <- d %>%
  filter(producer_age != 'photo') %>% # don't look at photo trials
  filter(recognizer_age != 'age2') %>%  # or 2-yr-olds
  mutate(recognizer_age_numeric = as.numeric(str_split_fixed(recognizer_age,'age',2)[,2])) %>% 
  mutate(recognizer_age_group = cut(recognizer_age_numeric, c(2.9, 4, 6, 8, 10.1), labels = c("3-4 yrs","5-6 yrs","7-8 yrs","9-10 yrs"))) %>%
  mutate(recognizer_age_group_numeric = cut(recognizer_age_numeric, c(2.9, 4, 6, 8, 10.1), labels=c(3,5,7,9))) %>%
  mutate(recognizer_age_group_numeric = as.numeric(recognizer_age_group_numeric))
```

### And wrangle sketch paths so can be joined with classification data outputs
```{r}
kids_sketches_d <- kids_sketches_d %>%
  mutate(sketch_path = as.factor(str_split_fixed(sketch_path,'/',2)[,2])) %>% 
  mutate(sketch_path = as.factor(str_split_fixed(sketch_path,'.png',2)[,1])) 
```

### Now also look at number of included subjects in each age group and experiment
```{r}
kids_sketches_d %>%
  group_by(recognizer_age_group,exp) %>%
  summarize(num_subs = length(unique(sessionId))) %>%
  kable()
```

# Basic descriptives and plots

## Examine recognition data

### Examine recognition by recognizer's age and experiment run 
```{r}
by_recognizer_filtered <- kids_sketches_d %>%
  group_by(recognizer_age, recognizer_age_numeric,exp) %>%
  multi_boot_standard(col = 'correct_or_not')

count_trials <- kids_sketches_d %>%
  group_by(recognizer_age) %>%
  summarize(count_trials = n())

by_recognizer_filtered$recognizer_age <- factor(by_recognizer_filtered$recognizer_age, levels = c('age2','age3','age4','age5','age6','age7','age8','age9','age10','adult'))

## Scale dots by number of trials in each bin to get a sense of variability
by_recognizer_filtered <-  by_recognizer_filtered %>%
  left_join(count_trials) %>%
  mutate(scale = count_trials / 1000) %>%
  group_by(exp)

ggplot(by_recognizer_filtered,aes(x=recognizer_age_numeric, y=mean, col = recognizer_age_numeric, size=scale)) +
  theme_few(base_size=18) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  geom_smooth(alpha=.2, color='grey') +
  scale_color_viridis(discrete = "FALSE") + 
  ylab('Proportion drawings recognized') +
  scale_size_area(max_size=1.5) +
  ylim(.25,.8) +
  xlab('Recognizer Age') +
  geom_hline(yintercept = .25, linetype="dashed") + 
  theme(axis.ticks.x = element_blank(), legend.position='none', aspect.ratio = 1) +
  facet_grid(~exp)
```

### Also visualize by recognizer age GROUP x experiment run
```{r}
## Doesn't seem quite right because there are such vastly different numbers of trials per kid.
# by_recognizer_filtered_age_group <- kids_sketches_d %>%
#   group_by(sessionId,recognizer_age_group,recognizer_age_group_numeric,exp) %>% 
#   summarize(indiv_photo_correct = mean(correct_or_not)) %>% # average first over individual participants
#   group_by(recognizer_age_group, recognizer_age_group_numeric,exp) %>%
#   multi_boot_standard(col = 'indiv_photo_correct')
# 
# count_subs_age_group <- kids_sketches_d %>%
#   distinct(sessionId,recognizer_age_group) %>%
#   group_by(recognizer_age_group) %>%
#   summarize(count_subs = n())

by_recognizer_filtered_age_group <- kids_sketches_d %>%
  group_by(recognizer_age_group,recognizer_age_group_numeric,exp) %>% 
  multi_boot_standard(col = 'correct_or_not')

count_trials_age_group <- kids_sketches_d %>%
  group_by(recognizer_age_group) %>%
  summarize(count_trials = n())

## Scale dots by number of trials in each bin to get a sense of variability
by_recognizer_filtered_age_group <-  by_recognizer_filtered_age_group %>%
  left_join(count_trials_age_group) %>%
  mutate(scale = count_trials) %>%
  group_by(exp)

ggplot(by_recognizer_filtered_age_group,aes(x=recognizer_age_group_numeric, y=mean, col = recognizer_age_group_numeric, size=scale)) +
  theme_few(base_size=18) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  # geom_smooth(alpha=.2, color='grey') +
  scale_color_viridis(discrete = "FALSE") + 
  ylab('Proportion drawings recognized') +
  scale_size_area(max_size=1.5) +
  ylim(.25,.8) +
  xlab('Recognizer Age Group') +
  geom_hline(yintercept = .25, linetype="dashed") + 
  theme(axis.ticks.x = element_blank(), legend.position='none', aspect.ratio = 1) +
  facet_grid(~exp)
```

### How does recognition vary with the age of the PRODUCER of the drawing? Goes up, as we would expect
```{r plot-counts}
# summarize avg correct by producer age  
by_producer <- d %>%
  filter(recognizer_age!= 'adult') %>%
  group_by(producer_age) %>%
  multi_boot_standard(col = 'correct_or_not')

ggplot(by_producer,aes(x=producer_age, y=mean, col = producer_age)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  scale_color_viridis(discrete = "TRUE") + 
  ylab('Proportion recognized') +
  theme_few()

```


### How does recognition break down by each category?
```{r}
both_category <- d %>%
  group_by(producer_age,intended_category) %>%
  multi_boot_standard(col = 'correct_or_not') 

ggplot(both_category,aes(x=producer_age, y=mean, col=producer_age)) +
  theme_few() + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  ylab('average correct') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), aspect.ratio = 1) +
  facet_wrap(~intended_category) +
  scale_color_viridis(discrete=TRUE) 

```

## Compute and plot recognition by sketch distinctiveness
We expect that the distintiveness of each drawing will be a major factor in how well it is recognized, and, further, that older children will be more sensitive to the presence of these distinctive features.

### Import classifications data (4-way classifications separetly for each run of recoggames)
```{r}
c_vehiclegame <- read.csv("compiled_classifications/classification-outputs-vehiclegame_C_0.1_460.csv") %>%
  as.tibble() %>%
  select(-X.1, -X) %>%
  mutate(denom = (airplane_prob + train_prob + boat_prob + car_prob) - target_label_prob) %>%
  mutate(log_odds = log(target_label_prob / denom)) %>% ## compute log odd probability
  mutate(exp='vehiclegame')

# now read it and join with other classifications  
c_animalgame <- read.csv("compiled_classifications/classification-outputs-animalgame_C_0.1_560.csv") %>%
  as.tibble() %>%
  select(-X.1, -X) %>%
  mutate(denom = (dog_prob + fish_prob + rabbit_prob + bird_prob) - target_label_prob) %>%
  mutate(log_odds = log(target_label_prob / denom)) %>%
  mutate(exp='animalgame') 

#
c_biganimalgame <- read.csv("compiled_classifications/classification-outputs-biganimalgame_C_0.1_600.csv") %>%
  as.tibble() %>%
  select(-X.1, -X) %>%
  mutate(denom = (bear_prob + sheep_prob + camel_prob + tiger_prob) - target_label_prob) %>%
  mutate(log_odds = log(target_label_prob / denom)) %>%
  mutate(exp='animalgame')


# now read it and join with other classifications  
c <- read.csv("compiled_classifications/classification-outputs-objectgame_C_0.1_500.csv") %>%
  as.tibble() %>%
  select(-X.1, -X) %>%
  mutate(denom = (bottle_prob + lamp_prob + hat_prob + cup_prob) - target_label_prob) %>%
  mutate(log_odds = log(target_label_prob / denom)) %>%
  mutate(exp='objectgame') %>% 
  full_join(c_vehiclegame) %>% 
  full_join(c_animalgame) %>%
  full_join(c_biganimalgame) %>%
  mutate(sketch_path = paste0(target_label,'_','sketch_age',age,'_cdm_',session_id)) %>%
  mutate(sketch_path = as.factor(sketch_path)) 
```

### Check how log-odds varies with target label probability and classifier outcome
```{r}
ggplot(c, aes(x=target_label_prob, y=log_odds, col=correct_or_not)) +
  geom_jitter(alpha=.1) +
  facet_wrap(~target_label) +
  theme_few()
```



```{r}
check <- c %>%
  group_by(target_label,age) %>%
  summarize(count_drawings = n())
```

## Compute distincitveness bins, join classifications & recognition data
```{r}
num_bins=10

## compute bins for distinctiveness
sketch_by_distinctiveness <- c %>%
  mutate(distinct_index = ntile(log_odds,num_bins)) %>% ## compute bins based on log odds over entire dataset
  select(sketch_path, distinct_index, log_odds)

## join distinctiveness bins for each sketch in dataset
all_joined <- kids_sketches_d %>%
  left_join(sketch_by_distinctiveness) 
```

## How does distinctiveness bin vary with classifier probability /correctness?
```{r}
ggplot(all_joined, aes(x=distinct_index, y=log_odds)) +
  geom_jitter(alpha=.03) +
  facet_wrap(~intended_category) +
  theme_few()
```

### Plot distinctivenss by item effects
```{r fig.width=6, fig.height=6}
distinct_by_item <- all_joined %>%
  group_by(intended_category, distinct_index) %>%
  multi_boot_standard(col='correct_or_not') %>%
  group_by(distinct_index)

ggplot(distinct_by_item, aes(x=distinct_index, y=mean, col=intended_category)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_smooth(alpha=.2, span=10, method='lm') +
  theme_few() +
  scale_x_continuous(breaks=seq(1,10,2)) +
  xlab('Distinctiveness Index') +
  ylab('Proportion recognized') +
  theme(legend.position='none') + 
  facet_wrap(~intended_category) 
  
```



### Plot distinctivenss by age interaction
```{r fig.width=8, fig.height=2}
distinct_by_age <- all_joined %>%
  group_by(recognizer_age_numeric, distinct_index) %>%
  filter(!is.na(distinct_index)) %>%
  multi_boot_standard(col='correct_or_not') %>%
  group_by(recognizer_age_numeric)

ggplot(distinct_by_age, aes(x=distinct_index, y=mean, col=recognizer_age_numeric)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), alpha=.4) +
  geom_smooth(alpha=.1, span=4, method='lm', aes(group=recognizer_age_numeric)) +
  facet_grid(~recognizer_age_numeric) +
  theme_few(base_size=18) + 
  theme(legend.position="none") +
  geom_hline(yintercept=.25, linetype='dashed',color='grey') +
  xlab('Age') +
  ylab('Proportion drawings recognized') +
  scale_color_viridis(discrete=FALSE) +
  scale_x_continuous(
    breaks=c(2,9),
    # labels=c('Least \n distinctive','Most \n distinctive')
    labels=c(' Least ',' Most ')
        ) +
  theme(axis.ticks.x=element_blank())
```


### Plot distinctivenss by age group interaction
```{r}
distinct_by_age_group <- all_joined %>%
  group_by(recognizer_age_group, distinct_index) %>%
  multi_boot_standard(col='correct_or_not') %>%
  group_by(distinct_index)

(distinct_by_age_plot <- ggplot(distinct_by_age_group, aes(x=distinct_index, y=mean, col=recognizer_age_group)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_smooth(alpha=.2, span=4, method='lm') +
  # facet_grid(~recognizer_age_group) +
  theme_few(base_size = 22) + 
  scale_x_continuous(breaks=seq(1,10,2)) +
  xlab('Distinctiveness Index') +
  ylab('Proportion recognized') +
  theme(legend.position='none') + 
  scale_color_viridis(discrete=TRUE)) 
  

# ggsave('DistinctByAge.svg',distinct_by_age_plot, width=11)
```


# Inferential statistics
### Examine how distinctivenss vs age group interact in glmer 
```{r}
model_glmer <- glmer(correct_or_not ~ scale(distinct_index)*scale(recognizer_age_group_numeric) + (distinct_index|intended_category) + (1|sessionId),  data = all_joined, family='binomial')
summary(model_glmer)
```


## Inferential model #2: Recognizer age as a continous variable
```{r}
model_glmer_age_cont <- glmer(correct_or_not ~ scale(distinct_index)*scale(recognizer_age_numeric) + (distinct_index|intended_category) + (1|sessionId),  data = all_joined, family='binomial')
summary(model_glmer_age_cont)

```



