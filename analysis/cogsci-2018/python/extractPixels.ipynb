{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(path, imsize=224, volatile=True, use_cuda=False):\n",
    "    im = Image.open(path)\n",
    "    im = RGBA2RGB(im)\n",
    "\n",
    "    # crop to sketch only (eliminate white space)\n",
    "    arr = np.asarray(im)\n",
    "    w,h,d = np.where(arr<255) # where the image is not white\n",
    "    if len(h)==0:\n",
    "        print(path)            \n",
    "    xlb = min(h)\n",
    "    xub = max(h)\n",
    "    ylb = min(w)\n",
    "    yub = max(w)\n",
    "    lb = min([xlb,ylb])\n",
    "    ub = max([xub,yub])            \n",
    "    im = im.crop((lb, lb, ub, ub))            \n",
    "\n",
    "    loader = transforms.Compose([\n",
    "        transforms.Pad(padding),                \n",
    "        transforms.Scale(imsize),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "    im = Variable(loader(im), volatile=volatile)\n",
    "    im = im.unsqueeze(0)\n",
    "    return im \n",
    "\n",
    "        \n",
    "def RGBA2RGB(image, color=(255, 255, 255)):\n",
    "    image.load()  # needed for split()\n",
    "    background = Image.new('RGB', image.size, color)\n",
    "    background.paste(image, mask=image.split()[3])  # 3 is the alpha channel\n",
    "    return background\n",
    "\n",
    "\n",
    "def list_files(path, ext='png'):\n",
    "        result = [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "        return result\n",
    "\n",
    "\n",
    "def get_metadata_from_path(path,cohort):\n",
    "    label = path.split('/')[-2]            \n",
    "    if cohort == 'kid':\n",
    "        age = path.split('/')[-1].split('_')[2]\n",
    "        session = path.split('/')[-1].split('.')[0].split('_')[-2] + '_' + path.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "    elif cohort == 'adult':\n",
    "        age = 'adult'\n",
    "        session = 'unknown'\n",
    "    else:\n",
    "        print('Need to specify a cohort: \"kid\" or \"adult\"!')\n",
    "        age = 'unknown'\n",
    "        session = 'unknown'\n",
    "    return label, age, session\n",
    "\n",
    "def check_invalid_sketch(filenames,invalids_path='drawings_to_exclude_clean.txt'):    \n",
    "    if not os.path.exists(invalids_path):\n",
    "        print('No file containing invalid paths at {}'.format(invalids_path))\n",
    "        invalids = []        \n",
    "    else:\n",
    "        x = pd.read_csv(invalids_path, header=None)\n",
    "        x.columns = ['filenames']\n",
    "        invalids = list(x.filenames.values)\n",
    "    valids = []   \n",
    "    basenames = [f.split('/')[-1] for f in filenames]\n",
    "    for i,f in enumerate(basenames):\n",
    "        if f not in invalids:\n",
    "            valids.append(filenames[i])\n",
    "    return valids\n",
    "\n",
    "def convert_age(Ages):\n",
    "    '''\n",
    "    handle trials where we didn't have age information\n",
    "    '''\n",
    "    ages = []\n",
    "    for a in Ages:\n",
    "        if len(a)>0:\n",
    "            ages.append(int(a))\n",
    "        else:\n",
    "            ages.append(-1)\n",
    "    return ages\n",
    "\n",
    "def make_dataframe(Labels,Ages,Sessions):    \n",
    "    Y = pd.DataFrame([Labels,Ages,Sessions])\n",
    "    Y = Y.transpose()\n",
    "    Y.columns = ['label','age','session']   \n",
    "    return Y\n",
    "\n",
    "\n",
    "def preprocess_features(Features, Y):\n",
    "    _Y = Y.sort_values(['label','age','session'])\n",
    "    inds = np.array(_Y.index)\n",
    "    _Features = normalize(Features[inds])\n",
    "    _Y = _Y.reset_index(drop=True) # reset pandas dataframe index\n",
    "    return _Features, _Y\n",
    "\n",
    "def normalize(X):\n",
    "    X = X - X.mean(0)\n",
    "    X = X / np.maximum(X.std(0), 1e-5)\n",
    "    return X\n",
    "\n",
    "## remove data where you dont have age information\n",
    "def remove_nans(Features, Y):\n",
    "    ind = Y.index[(Y['age'] > 0)]\n",
    "    _Y = Y.loc[ind]\n",
    "    _Features = Features[ind.tolist()]\n",
    "    return _Features, _Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###  Path to adult sketches\n",
    "data_path = '/data2/jefan/quickDraw/png_micro'\n",
    "all_adult_pngs = list_files(data_path)\n",
    "imSize=224\n",
    "numPixels=imSize*imSize\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Adult features\n",
    "Labels = []\n",
    "Ages = []\n",
    "Sessions = []\n",
    "Features = np.zeros((len(all_adult_pngs),numPixels))\n",
    "\n",
    "for vi, v in enumerate(np.asarray(all_adult_pngs)):\n",
    "    im = Image.open(v)\n",
    "    im = RGBA2RGB(im)\n",
    "    im2 = im.resize((224,224), Image.ANTIALIAS)\n",
    "    arr = np.array(im2)\n",
    "    oneChannel = arr[:,:,1];\n",
    "    pixels = np.ravel(oneChannel)\n",
    "    Features[vi,:] = pixels\n",
    "    label, age, session = get_metadata_from_path(v,'adult')\n",
    "    Labels.append(label)\n",
    "    Ages.append(age)\n",
    "    Sessions.append(session)\n",
    "    \n",
    "Y = make_dataframe(Labels,Ages,Sessions)\n",
    "_Features, _Y = preprocess_features(Features, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save adult pixels\n",
    "cohort='adult'\n",
    "np.save('./features/FEATURES_{}_{}.npy'.format('pixels', cohort), _Features)\n",
    "_Y.to_csv('./features/METADATA_{}.csv'.format(cohort))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190668800"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(_Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sketch_paths after filtering: 462\n"
     ]
    }
   ],
   "source": [
    "## Now for kid features\n",
    "data_path_kids = '/home/jefan/kiddraw/analysis/museumdraw/sketches'\n",
    "all_pngs_kids = list_files(data_path_kids)\n",
    "\n",
    "\n",
    "## filter out invalid sketches\n",
    "all_pngs_kids = check_invalid_sketch(all_pngs_kids)\n",
    "print('Length of sketch_paths after filtering: {}'.format(len(all_pngs_kids)))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Kid features\n",
    "Labels = []\n",
    "Ages = []\n",
    "Sessions = []\n",
    "Features = np.zeros((len(all_pngs_kids),numPixels))\n",
    "\n",
    "for vi, v in enumerate(np.asarray(all_pngs_kids)):\n",
    "    im = Image.open(v)\n",
    "    im = RGBA2RGB(im)\n",
    "    im2 = im.resize((224,224), Image.ANTIALIAS)\n",
    "    arr = np.array(im2)\n",
    "    oneChannel = arr[:,:,1];\n",
    "    pixels = np.ravel(oneChannel)\n",
    "    Features[vi,:] = pixels\n",
    "    label, age, session = get_metadata_from_path(v,'kid')\n",
    "    Labels.append(label)\n",
    "    Ages.append(age)\n",
    "    Sessions.append(session)\n",
    "   \n",
    "\n",
    "Ages = convert_age(Ages)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# organize metadata into dataframe\n",
    "Y = make_dataframe(Labels,Ages,Sessions)\n",
    "_Features, _Y = preprocess_features(Features, Y)\n",
    "_Features, _Y = remove_nans(_Features, _Y)  # remove nans from kid dataframe (where we didn't have age information)\n",
    "\n",
    "cohort='kid'\n",
    "np.save('./features/FEATURES_{}_{}.npy'.format('pixels', cohort), _Features)\n",
    "_Y.to_csv('./features/METADATA_{}.csv'.format(cohort))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
